{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import base64\n",
    "import pymongo\n",
    "from collections import Counter\n",
    "import re\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_string=\"mongodb://localhost:27017\"\n",
    "yapraksila_ozturk=pymongo.MongoClient(connection_string)\n",
    "database=yapraksila_ozturk[\"scrapeDB\"]\n",
    "collection=database[\"news\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=[]\n",
    "data_of={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection=database[\"word_frequency\"]\n",
    "word_data=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://turkishnetworktimes.com/kategori/gundem/\"\n",
    "response=requests.get(url)\n",
    "response=response.content\n",
    "response\n",
    "soup=BeautifulSoup(response, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostFrequentWords(all_text):\n",
    "    words = re.findall('\\w+', all_text)\n",
    "    common=Counter(words).most_common(10)\n",
    "    word_data.append(common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractData(get_url):\n",
    "    url=get_url\n",
    "    response=requests.get(url)\n",
    "    response=response.content\n",
    "    soup=BeautifulSoup(response, 'html.parser')\n",
    "    inside=soup.find(\"div\", {\"class\":\"yazi_icerik\"})\n",
    "    text_inside=inside.find_all(\"p\")\n",
    "    for i in text_inside:\n",
    "        data_of[\"text\"]=i.text_inside\n",
    "        #print(i.text)\n",
    "        all_text=\" \"+i.text\n",
    "    date=soup.find_all(\"span\", {\"class\":\"tarih\"})\n",
    "    for i in date:\n",
    "        publish=i.find(\"time\").get(\"datetime\")\n",
    "        update=i.find_next(\"time\").get(\"datetime\")\n",
    "    data_of[\"publish_date\"]=publish\n",
    "    data_of[\"update_date\"]=update\n",
    "    data.append(data_of)\n",
    "    mostFrequentWords(all_text)\n",
    "    #print(publish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all news from each page and extract data\n",
    "def getEachNews(soup):\n",
    "    page=soup.find(\"div\", {\"class\":\"kategori_yazilist\"})\n",
    "    page=page.find_all(\"article\", {\"class\":\"col-12\"})\n",
    "    for i in page:\n",
    "        get_url=i.find('a',{\"class\":\"post-link\"})['href']\n",
    "        get_img=i.find('img').get('src')\n",
    "        strOne = get_img.partition(\",\")[2]\n",
    "        encoded_image = base64.b64decode(strOne)\n",
    "        header=i.find('h2', {\"class\":\"haber-baslik\"}).text\n",
    "        #print(header)\n",
    "        data_of[\"url\"]=get_url\n",
    "        data_of[\"header\"]=header\n",
    "        data_of[\"image_url_list\"]=encoded_image\n",
    "        extractData(get_url)\n",
    "        data.append(data_of)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the first 50 pages\n",
    "url=\"https://turkishnetworktimes.com/kategori/gundem/\"\n",
    "i=0\n",
    "data=[]\n",
    "data_of={}\n",
    "while(i<49):\n",
    "    if(i==0):\n",
    "        response=requests.get(url)\n",
    "    else:\n",
    "        response=requests.get(next_url)\n",
    "    response=response.content\n",
    "    soup=BeautifulSoup(response, 'html.parser', from_encoding=\"utf-8\")\n",
    "    getEachNews(soup)\n",
    "    \n",
    "    next_page=soup.find(\"a\", {\"class\":\"next page-numbers\"})\n",
    "    if next_page:\n",
    "        next_url=next_page.get(\"href\")\n",
    "        #print(next_url)\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insert data into database\n",
    "for i in data:\n",
    "   x=collection.insert_one(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
